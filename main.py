import os
import pandas as pd
from preprocessing import on_isleme_pipeline

# GiriÅŸ dosyasÄ±nÄ±n adÄ±
input_file = "birlesik_sozluk.csv"
output_file = "yorumlar_on_islemli.csv"

# DosyanÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
if not os.path.exists(input_file):
    print(f"âŒ HATA: '{input_file}' dosyasÄ± bulunamadÄ±.")
    exit()

# DosyayÄ± oku
try:
    df = pd.read_csv(input_file, encoding="utf-8", sep=",", engine="python", quotechar='"', on_bad_lines='skip')
except UnicodeDecodeError:
    print("âš ï¸ UTF-8 ile okunamadÄ±, ISO-8859-9 ile tekrar deneniyor...")
    try:
        df = pd.read_csv(input_file, encoding="ISO-8859-9", sep=",", engine="python", quotechar='"',
                         on_bad_lines='skip')
    except Exception as e:
        print(f"âŒ Dosya okuma hatasÄ±: {e}")
        exit()
except Exception as e:
    print(f"âŒ Dosya okuma hatasÄ±: {e}")
    exit()

# SÃ¼tun adlarÄ±nÄ± kontrol et ve normalize et
print("SÃ¼tun adlarÄ±:", df.columns)
df.columns = df.columns.str.strip().str.lower()  # BoÅŸluklarÄ± kaldÄ±r, kÃ¼Ã§Ã¼k harfe Ã§evir

# "kelime" ve "anlam" sÃ¼tununun varlÄ±ÄŸÄ±nÄ± kontrol et
if "kelime" not in df.columns or "anlam" not in df.columns:
    print("âŒ HATA: 'kelime' veya 'anlam' sÃ¼tunu bulunamadÄ±. Mevcut sÃ¼tunlar:", df.columns)
    exit()

# Yeni sÃ¼tunlar iÃ§in listeler
lowercase_list = []
tokens_list = []
lemmas_list = []
stemmed_list = []

# Her yoruma Ã¶n iÅŸleme uygula
print("ğŸ”„ Yorumlar iÅŸleniyor...")
for i, anlam in enumerate(df["anlam"]):
    try:
        anlam_str = str(anlam)

        # Tokenize etmeden Ã¶nce tekrar eden kelimeleri engellemek iÃ§in her kelimeyi eÅŸsiz yapÄ±yoruz
        kelimeler = anlam_str.split()  # Anlamdaki kelimeleri ayÄ±r
        kelimeler = list(set(kelimeler))  # 'set' kullanarak benzersiz hale getir
        anlam_str = " ".join(kelimeler)  # TekrarlarÄ± engellenmiÅŸ anlam

        # Pipeline iÅŸleminden sonra anlamÄ±n yeniden dÃ¼zenlenmesi
        sonuc = on_isleme_pipeline(anlam_str)

        # Her bir iÅŸlemde, bir anlam iÃ§in 5 tane tekrar edilmesini engellemek
        lowercase_list.append(sonuc["lowercase"])
        tokens_list.append(" ".join(sorted(set(sonuc["tokens"]))))  # Tokenleri benzersiz yap
        lemmas_list.append(" ".join(sorted(set(sonuc["lemmas"]))))  # Lemmatize edilmiÅŸ kelimeleri benzersiz yap
        stemmed_list.append(" ".join(sorted(set(sonuc["stemmed"]))))  # Stemmed kelimeleri benzersiz yap

    except Exception as e:
        print(f"âš ï¸ {i}. anlam iÅŸlenemedi: {e}")
        lowercase_list.append("")
        tokens_list.append("")
        lemmas_list.append("")
        stemmed_list.append("")

# SonuÃ§larÄ± yeni sÃ¼tunlara ekle
df["lowercase"] = lowercase_list
df["tokens"] = tokens_list
df["lemmas"] = lemmas_list
df["stemmed"] = stemmed_list

# Yeni CSV olarak kaydet
try:
    df.to_csv(output_file, index=False, encoding="utf-8", sep=";", quotechar='"')
    print("âœ… TÃ¼m yorumlara Ã¶n iÅŸleme baÅŸarÄ±yla uygulandÄ± ve 'yorumlar_on_islemli.csv' dosyasÄ±na kaydedildi.")
except Exception as e:
    print(f"âŒ CSV kaydetme hatasÄ±: {e}")
